{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"crypto_currency_prediction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNvvycUd0LKE+w7bsGPRlXi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GGaqC0eRSuR2","colab_type":"code","outputId":"f9e0af0f-f6d4-45a9-d27d-c0d32addec91","executionInfo":{"status":"ok","timestamp":1591643201366,"user_tz":-330,"elapsed":585553,"user":{"displayName":"himanshu kishnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6Q3fFj-jBzmPUci-lcpaU8wRKsA78gnsHi8xPA=s64","userId":"04464309454633296729"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":177}},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n"],"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-14805fe1-c198-43bb-84c9-701ca93561b8\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-14805fe1-c198-43bb-84c9-701ca93561b8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving BCH-USD.csv to BCH-USD (3).csv\n","Saving BTC-USD.csv to BTC-USD (3).csv\n","Saving ETH-USD.csv to ETH-USD (3).csv\n","Saving LTC-USD.csv to LTC-USD (3).csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"micPE5O0DUP4","colab_type":"code","colab":{}},"source":["# Load the TensorBoard notebook extension\n","%reload_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_qCXK6WDXhe","colab_type":"code","colab":{}},"source":["# Clear any logs from previous runs\n","!rm -rf ./logs/ "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CtA0vhQzQfkX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"a95f38b1-06a5-4ab6-ab07-53496fc02617","executionInfo":{"status":"ok","timestamp":1591643270906,"user_tz":-330,"elapsed":26090,"user":{"displayName":"himanshu kishnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6Q3fFj-jBzmPUci-lcpaU8wRKsA78gnsHi8xPA=s64","userId":"04464309454633296729"}}},"source":["!pip install tensorboardcolab\n","from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n","\n","tbc=TensorBoardColab()"],"execution_count":74,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://191e80f9c493.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xGg78PuKDbc5","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorboard.plugins.hparams import api as hp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xedk-5UHi6CU","colab_type":"code","outputId":"425c658c-22a9-4eee-b156-e487e13d8deb","executionInfo":{"status":"ok","timestamp":1591643270909,"user_tz":-330,"elapsed":21581,"user":{"displayName":"himanshu kishnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6Q3fFj-jBzmPUci-lcpaU8wRKsA78gnsHi8xPA=s64","userId":"04464309454633296729"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tC5FPTPsjFkV","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import timeit\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print(\n","      '\\n\\nThis error most likely means that this notebook is not '\n","      'configured to use a GPU.  Change this in Notebook Settings via the '\n","      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n","  raise SystemError('GPU device not found')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQeiJdUhT25Q","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from sklearn import preprocessing\n","from random import shuffle\n","from collections import deque\n","import numpy as np\n","import time\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.keras.layers import Dropout, Dense, LSTM, BatchNormalization\n","import os\n","import io\n","from tensorboard.plugins.hparams import api as hp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uy1qHgZU9DG","colab_type":"code","colab":{}},"source":["SEQ_LEN = 60\n","FUTURE_PERIOD_PREDICT = 3\n","RATIO_TO_PREDICT = \"LTC-USD\"\n","BATCH_SIZE = 64\n","EPOCHS = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-sEs135Ds3o","colab_type":"code","colab":{}},"source":["HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32, 64]))\n","HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n","HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd','adamax']))\n","\n","METRIC_ACCURACY = 'accuracy'\n","\n","with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n","  hp.hparams_config(\n","    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n","    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n","  )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-OGG0fbWZiw","colab_type":"code","colab":{}},"source":["def classify(current, future):\n","    if float(future) > float(current):\n","        return 1\n","    else:\n","        return 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6gFyfw0Wfes","colab_type":"code","colab":{}},"source":["def preprocess_df(df):\n","    df = df.drop(\"future\",1)\n","    \n","    for col in df.columns:\n","        if col != \"target\":\n","            df[col] = df[col].pct_change()\n","            df.dropna(inplace=True)\n","            df[col] = preprocessing.scale(df[col].values)\n","            \n","    df.dropna(inplace=True)\n","    \n","    sequential_data = []\n","    prev_mins = deque(maxlen = SEQ_LEN)\n","\n","    for value in df.values:\n","        prev_mins.append([n for n in value[:-1]])\n","        if len(prev_mins) == SEQ_LEN:\n","            sequential_data.append([np.array(prev_mins), value[-1]])\n","        \n","    shuffle(sequential_data)\n","    buys = []\n","    sells = []\n","    \n","    for seq, target in sequential_data:\n","        if target == 0:\n","            sells.append([seq, target])\n","            \n","        elif target == 1:\n","            buys.append([seq, target])\n","    \n","    shuffle(buys)\n","    shuffle(sells)\n","    \n","    lower = min(len(buys), len(sells))\n","    \n","    buys = buys[:lower]\n","    sells = sells[:lower]\n","    \n","    sequential_data = buys + sells\n","    shuffle(sequential_data)\n","    \n","    X = []\n","    y = []\n","    for seq, target in sequential_data:\n","        X.append(seq)\n","        y.append(target)\n","    return np.array(X), y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"phkoGakzVAm1","colab_type":"code","outputId":"1e7a3a1d-9697-48d0-ff0d-f80ad32caf34","executionInfo":{"status":"ok","timestamp":1591643335770,"user_tz":-330,"elapsed":8730,"user":{"displayName":"himanshu kishnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6Q3fFj-jBzmPUci-lcpaU8wRKsA78gnsHi8xPA=s64","userId":"04464309454633296729"}},"colab":{"base_uri":"https://localhost:8080/","height":307}},"source":["main_df = pd.DataFrame()\n","ratios = [\"BTC-USD\", \"LTC-USD\", \"ETH-USD\", \"BCH-USD\"]\n","for ratio in ratios:\n","    print(ratio)\n","    dataset = f\"{ratio}.csv\"\n","    df = pd.read_csv(io.BytesIO(uploaded[dataset]), names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volume\"])\n","    df.rename(columns = {\"close\": f\"{ratio}_close\", \"volume\":f\"{ratio}_volume\"}, inplace = True)\n","    df.set_index(\"time\", inplace=True)\n","    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n","    \n","    if len(main_df)==0:\n","        main_df = df\n","    else:\n","        main_df = main_df.join(df)       \n","\n","\n","main_df.fillna(method = \"ffill\", inplace = True)\n","main_df.dropna(inplace = True)\n","\n","main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n","main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n","\n","\n","print(main_df[[f\"{RATIO_TO_PREDICT}_close\", \"future\", \"target\"]].head(10))\n","\n","times = sorted(main_df.index.values)\n","last_5pct = times[-int(0.05*len(times))]\n","print(last_5pct)\n","\n","validation_main_df = main_df[(main_df.index >= last_5pct)]\n","main_df = main_df[(main_df.index < last_5pct)]\n","\n","train_x, train_y = preprocess_df(main_df)\n","validation_x, validation_y = preprocess_df(validation_main_df)"],"execution_count":84,"outputs":[{"output_type":"stream","text":["BTC-USD\n","LTC-USD\n","ETH-USD\n","BCH-USD\n","            LTC-USD_close     future  target\n","time                                        \n","1528968720      96.660004  96.389999       0\n","1528968780      96.570000  96.519997       0\n","1528968840      96.500000  96.440002       0\n","1528968900      96.389999  96.470001       1\n","1528968960      96.519997  96.400002       0\n","1528969020      96.440002  96.400002       0\n","1528969080      96.470001  96.400002       0\n","1528969140      96.400002  96.400002       0\n","1528969200      96.400002  96.400002       0\n","1528969260      96.400002  96.449997       1\n","1534922100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"id021GsAWn4S","colab_type":"code","outputId":"0d9f4c95-f81b-4cf4-824f-39db0faa3ac5","executionInfo":{"status":"ok","timestamp":1591643351437,"user_tz":-330,"elapsed":1591,"user":{"displayName":"himanshu kishnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6Q3fFj-jBzmPUci-lcpaU8wRKsA78gnsHi8xPA=s64","userId":"04464309454633296729"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n","print(f\"Don't buys: {train_y.count(0)}, buys:{train_y.count(1)}\")\n","print(f\"VALIDATION Don't buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"],"execution_count":85,"outputs":[{"output_type":"stream","text":["train data: 77922 validation: 3860\n","Don't buys: 38961, buys:38961\n","VALIDATION Don't buys: 1930, buys: 1930\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t6iUt7WKPuR_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"962GNbdFJhZD","colab_type":"code","colab":{}},"source":["def train_test_model(hparams):\n","  model = Sequential()\n","  model.add(LSTM(hparams[HP_NUM_UNITS], input_shape=(train_x.shape[1:]), return_sequences=True))\n","  model.add(Dropout(hparams[HP_DROPOUT]))\n","  model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n","\n","  model.add(LSTM(hparams[HP_NUM_UNITS], return_sequences=True))\n","  model.add(Dropout(hparams[HP_DROPOUT]))\n","  model.add(BatchNormalization())\n","\n","  model.add(LSTM(hparams[HP_NUM_UNITS]))\n","  model.add(Dropout(hparams[HP_DROPOUT]))\n","  model.add(BatchNormalization())\n","\n","  model.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n","  model.add(Dropout(hparams[HP_DROPOUT]))\n","\n","  model.add(Dense(2, activation='softmax'))\n","\n","  model.compile(optimizer=hparams[HP_OPTIMIZER],\n","                loss ='sparse_categorical_crossentropy',\n","                metrics = ['accuracy']\n","                )\n","  NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n","\n","  log_dir= os.path.join('logs',\"{}\".format(NAME))\n","  tensorboard = TensorBoard(log_dir=log_dir)\n","\n","  model.fit(\n","      np.array(train_x), np.array(train_y),\n","      batch_size=BATCH_SIZE,\n","      epochs=EPOCHS,\n","      callbacks = [tf.keras.callbacks.TensorBoard(log_dir),\n","      hp.KerasCallback(log_dir,hparams)\n","      ]\n","  )\n","  _, accuracy = model.evaluate(np.array(validation_x),np.array(validation_y))\n","  return accuracy\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRjb3qzgJRx0","colab_type":"code","colab":{}},"source":["def run(run_dir, hparams):\n","  with tf.summary.create_file_writer(run_dir).as_default():\n","    hp.hparams(hparams)  # record the values used in this trial\n","    accuracy = train_test_model(hparams)\n","    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ws6ivHRhPIYQ","colab_type":"code","colab":{}},"source":["%tensorboard --logdir logs/hparam_tuning"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LJZ_3mYJFQL","colab_type":"code","outputId":"8ce2ad9d-ee9c-449a-ddb6-9f6a3919f6f2","executionInfo":{"status":"error","timestamp":1591642495380,"user_tz":-330,"elapsed":5283,"user":{"displayName":"himanshu kishnani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQ6Q3fFj-jBzmPUci-lcpaU8wRKsA78gnsHi8xPA=s64","userId":"04464309454633296729"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["session_num = 0\n","\n","for num_units in HP_NUM_UNITS.domain.values:\n","  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n","    for optimizer in HP_OPTIMIZER.domain.values:\n","      hparams = {\n","          HP_NUM_UNITS: num_units,\n","          HP_DROPOUT: dropout_rate,\n","          HP_OPTIMIZER: optimizer,\n","      }\n","      run_name = \"run-%d\" % session_num\n","      print('--- Starting trial: %s' % run_name)\n","      print({h.name: hparams[h] for h in hparams})\n","      run('logs/hparam_tuning/' + run_name, hparams)\n","      session_num += 1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--- Starting trial: run-0\n","{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n","Epoch 1/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.7022 - accuracy: 0.5242\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6891 - accuracy: 0.5385\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6865 - accuracy: 0.5468\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6843 - accuracy: 0.5525\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6815 - accuracy: 0.5589\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6800 - accuracy: 0.5648\n","Epoch 7/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6786 - accuracy: 0.5681\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6771 - accuracy: 0.5708\n","Epoch 9/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6760 - accuracy: 0.5744\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6745 - accuracy: 0.5768\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6734 - accuracy: 0.5779\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6715 - accuracy: 0.5831\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6706 - accuracy: 0.5847\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6699 - accuracy: 0.5847\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6681 - accuracy: 0.5901\n","Epoch 16/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6663 - accuracy: 0.5914\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6662 - accuracy: 0.5922\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6648 - accuracy: 0.5967\n","Epoch 19/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6638 - accuracy: 0.5975\n","Epoch 20/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6624 - accuracy: 0.5991\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6990 - accuracy: 0.5554\n","--- Starting trial: run-1\n","{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adamax'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:15 - loss: 1.1559 - accuracy: 0.4297WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.100900). Check your callbacks.\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.7170 - accuracy: 0.5186\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6935 - accuracy: 0.5279\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6891 - accuracy: 0.5376\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6879 - accuracy: 0.5428\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6865 - accuracy: 0.5474\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6856 - accuracy: 0.5513\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6841 - accuracy: 0.5536\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6837 - accuracy: 0.5561\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6819 - accuracy: 0.5614\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6811 - accuracy: 0.5626\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6803 - accuracy: 0.5652\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6785 - accuracy: 0.5719\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6778 - accuracy: 0.5735\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6771 - accuracy: 0.5725\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6770 - accuracy: 0.5726\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6760 - accuracy: 0.5766\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6751 - accuracy: 0.5777\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6750 - accuracy: 0.5750\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6749 - accuracy: 0.5785\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6740 - accuracy: 0.5818\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6767 - accuracy: 0.5720\n","--- Starting trial: run-2\n","{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:15 - loss: 0.7911 - accuracy: 0.4688WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.100491). Check your callbacks.\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.7093 - accuracy: 0.5157\n","Epoch 2/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6944 - accuracy: 0.5251\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6913 - accuracy: 0.5291\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6906 - accuracy: 0.5320\n","Epoch 5/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6904 - accuracy: 0.5344\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6894 - accuracy: 0.5362\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6887 - accuracy: 0.5393\n","Epoch 8/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6888 - accuracy: 0.5416\n","Epoch 9/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6882 - accuracy: 0.5434\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6879 - accuracy: 0.5422\n","Epoch 11/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6880 - accuracy: 0.5404\n","Epoch 12/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6875 - accuracy: 0.5434\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6874 - accuracy: 0.5436\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6872 - accuracy: 0.5434\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6873 - accuracy: 0.5445\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6868 - accuracy: 0.5444\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6865 - accuracy: 0.5470\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6865 - accuracy: 0.5451\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6861 - accuracy: 0.5475\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6861 - accuracy: 0.5468\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6850 - accuracy: 0.5536\n","--- Starting trial: run-3\n","{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.7102 - accuracy: 0.5144\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6906 - accuracy: 0.5315\n","Epoch 3/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6883 - accuracy: 0.5402\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6869 - accuracy: 0.5444\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6845 - accuracy: 0.5536\n","Epoch 6/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6829 - accuracy: 0.5599\n","Epoch 7/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6808 - accuracy: 0.5666\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6800 - accuracy: 0.5661\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6788 - accuracy: 0.5685\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6788 - accuracy: 0.5728\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6777 - accuracy: 0.5727\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6773 - accuracy: 0.5727\n","Epoch 13/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6762 - accuracy: 0.5739\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6750 - accuracy: 0.5786\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6743 - accuracy: 0.5802\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6741 - accuracy: 0.5828\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6727 - accuracy: 0.5826\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6721 - accuracy: 0.5827\n","Epoch 19/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6715 - accuracy: 0.5841\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6707 - accuracy: 0.5857\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6728 - accuracy: 0.5834\n","--- Starting trial: run-4\n","{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adamax'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.7244 - accuracy: 0.5163\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6933 - accuracy: 0.5251\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6906 - accuracy: 0.5327\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6884 - accuracy: 0.5407\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6877 - accuracy: 0.5429\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6867 - accuracy: 0.5465\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6859 - accuracy: 0.5478\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6847 - accuracy: 0.5506\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6842 - accuracy: 0.5537\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6827 - accuracy: 0.5577\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6827 - accuracy: 0.5578\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6815 - accuracy: 0.5612\n","Epoch 13/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6812 - accuracy: 0.5641\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6813 - accuracy: 0.5607\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6804 - accuracy: 0.5653\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6802 - accuracy: 0.5664\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6786 - accuracy: 0.5699\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6792 - accuracy: 0.5665\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6787 - accuracy: 0.5724\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6781 - accuracy: 0.5697\n","121/121 [==============================] - 1s 8ms/step - loss: 0.6753 - accuracy: 0.5767\n","--- Starting trial: run-5\n","{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.7152 - accuracy: 0.5118\n","Epoch 2/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6941 - accuracy: 0.5180\n","Epoch 3/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6922 - accuracy: 0.5252\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6907 - accuracy: 0.5319\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6904 - accuracy: 0.5289\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6904 - accuracy: 0.5330\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6900 - accuracy: 0.5354\n","Epoch 8/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6895 - accuracy: 0.5358\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6894 - accuracy: 0.5348\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6893 - accuracy: 0.5366\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6891 - accuracy: 0.5378\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6890 - accuracy: 0.5364\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6893 - accuracy: 0.5375\n","Epoch 14/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6888 - accuracy: 0.5402\n","Epoch 15/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6887 - accuracy: 0.5393\n","Epoch 16/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6886 - accuracy: 0.5386\n","Epoch 17/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6885 - accuracy: 0.5380\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6881 - accuracy: 0.5428\n","Epoch 19/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6885 - accuracy: 0.5412\n","Epoch 20/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6882 - accuracy: 0.5421\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6870 - accuracy: 0.5412\n","--- Starting trial: run-6\n","{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.7033 - accuracy: 0.5266\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6873 - accuracy: 0.5453\n","Epoch 3/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6837 - accuracy: 0.5546\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6803 - accuracy: 0.5648\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6784 - accuracy: 0.5711\n","Epoch 6/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6764 - accuracy: 0.5735\n","Epoch 7/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6735 - accuracy: 0.5786\n","Epoch 8/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6715 - accuracy: 0.5853\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6684 - accuracy: 0.5908\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6647 - accuracy: 0.5960\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6613 - accuracy: 0.6014\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6571 - accuracy: 0.6083\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6532 - accuracy: 0.6131\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6503 - accuracy: 0.6179\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6461 - accuracy: 0.6230\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6410 - accuracy: 0.6283\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6382 - accuracy: 0.6333\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6339 - accuracy: 0.6349\n","Epoch 19/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6298 - accuracy: 0.6407\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6271 - accuracy: 0.6447\n","121/121 [==============================] - 1s 7ms/step - loss: 0.7373 - accuracy: 0.5407\n","--- Starting trial: run-7\n","{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adamax'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.7108 - accuracy: 0.5214\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6915 - accuracy: 0.5353\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6872 - accuracy: 0.5451\n","Epoch 4/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6846 - accuracy: 0.5508\n","Epoch 5/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6818 - accuracy: 0.5596\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6793 - accuracy: 0.5650\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6775 - accuracy: 0.5719\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6754 - accuracy: 0.5757\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6736 - accuracy: 0.5814\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6714 - accuracy: 0.5841\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6697 - accuracy: 0.5868\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6678 - accuracy: 0.5910\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6651 - accuracy: 0.5945\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6632 - accuracy: 0.5995\n","Epoch 15/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6617 - accuracy: 0.5999\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6595 - accuracy: 0.6037\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6575 - accuracy: 0.6060\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6558 - accuracy: 0.6075\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6542 - accuracy: 0.6120\n","Epoch 20/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6514 - accuracy: 0.6159\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6977 - accuracy: 0.5531\n","--- Starting trial: run-8\n","{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:34 - loss: 0.8537 - accuracy: 0.5078WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.112949). Check your callbacks.\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.7142 - accuracy: 0.5169\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6950 - accuracy: 0.5291\n","Epoch 3/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6914 - accuracy: 0.5324\n","Epoch 4/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6885 - accuracy: 0.5401\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6874 - accuracy: 0.5439\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6870 - accuracy: 0.5457\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6867 - accuracy: 0.5457\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6856 - accuracy: 0.5505\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6857 - accuracy: 0.5502\n","Epoch 10/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6852 - accuracy: 0.5520\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6855 - accuracy: 0.5500\n","Epoch 12/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6843 - accuracy: 0.5529\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6849 - accuracy: 0.5499\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6841 - accuracy: 0.5530\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6836 - accuracy: 0.5535\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6839 - accuracy: 0.5549\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6836 - accuracy: 0.5542\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6832 - accuracy: 0.5553\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6831 - accuracy: 0.5551\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6823 - accuracy: 0.5579\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6838 - accuracy: 0.5415\n","--- Starting trial: run-9\n","{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.7024 - accuracy: 0.5189\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6891 - accuracy: 0.5377\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6861 - accuracy: 0.5518\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6827 - accuracy: 0.5615\n","Epoch 5/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6807 - accuracy: 0.5653\n","Epoch 6/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6788 - accuracy: 0.5685\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6775 - accuracy: 0.5698\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6759 - accuracy: 0.5761\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6741 - accuracy: 0.5796\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6728 - accuracy: 0.5823\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6708 - accuracy: 0.5846\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6679 - accuracy: 0.5916\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6666 - accuracy: 0.5929\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6632 - accuracy: 0.5985\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6612 - accuracy: 0.6023\n","Epoch 16/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6590 - accuracy: 0.6044\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6580 - accuracy: 0.6063\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6555 - accuracy: 0.6095\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6532 - accuracy: 0.6139\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6513 - accuracy: 0.6155\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6935 - accuracy: 0.5570\n","--- Starting trial: run-10\n","{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adamax'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:26 - loss: 0.9643 - accuracy: 0.4609WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.106589). Check your callbacks.\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.7217 - accuracy: 0.5165\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6937 - accuracy: 0.5267\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6889 - accuracy: 0.5365\n","Epoch 4/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6867 - accuracy: 0.5462\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6840 - accuracy: 0.5542\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6821 - accuracy: 0.5583\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6809 - accuracy: 0.5624\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6790 - accuracy: 0.5669\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6784 - accuracy: 0.5678\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6764 - accuracy: 0.5741\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6759 - accuracy: 0.5749\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6745 - accuracy: 0.5778\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6734 - accuracy: 0.5796\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6724 - accuracy: 0.5818\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6713 - accuracy: 0.5823\n","Epoch 16/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6695 - accuracy: 0.5853\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6695 - accuracy: 0.5870\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6686 - accuracy: 0.5887\n","Epoch 19/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6663 - accuracy: 0.5912\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6650 - accuracy: 0.5944\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6891 - accuracy: 0.5630\n","--- Starting trial: run-11\n","{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:31 - loss: 0.8195 - accuracy: 0.5312WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.113241). Check your callbacks.\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.7214 - accuracy: 0.5123\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6941 - accuracy: 0.5241\n","Epoch 3/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6909 - accuracy: 0.5296\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6899 - accuracy: 0.5345\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6896 - accuracy: 0.5348\n","Epoch 6/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6892 - accuracy: 0.5372\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6889 - accuracy: 0.5388\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6885 - accuracy: 0.5378\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6885 - accuracy: 0.5392\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6882 - accuracy: 0.5409\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6880 - accuracy: 0.5411\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6880 - accuracy: 0.5404\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6880 - accuracy: 0.5403\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6871 - accuracy: 0.5444\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6877 - accuracy: 0.5426\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6874 - accuracy: 0.5440\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6867 - accuracy: 0.5466\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6868 - accuracy: 0.5463\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6868 - accuracy: 0.5452\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6866 - accuracy: 0.5463\n","121/121 [==============================] - 1s 8ms/step - loss: 0.6845 - accuracy: 0.5425\n","--- Starting trial: run-12\n","{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adam'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.7030 - accuracy: 0.5268\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6853 - accuracy: 0.5510\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6817 - accuracy: 0.5608\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6790 - accuracy: 0.5715\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6766 - accuracy: 0.5735\n","Epoch 6/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6735 - accuracy: 0.5797\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6701 - accuracy: 0.5876\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6650 - accuracy: 0.5963\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6586 - accuracy: 0.6063\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6513 - accuracy: 0.6172\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6422 - accuracy: 0.6286\n","Epoch 12/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6309 - accuracy: 0.6395\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6213 - accuracy: 0.6520\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6106 - accuracy: 0.6628\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.5999 - accuracy: 0.6717\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.5914 - accuracy: 0.6787\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.5814 - accuracy: 0.6897\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.5723 - accuracy: 0.6957\n","Epoch 19/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.5644 - accuracy: 0.7042\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.5552 - accuracy: 0.7121\n","121/121 [==============================] - 1s 7ms/step - loss: 0.8462 - accuracy: 0.5394\n","--- Starting trial: run-13\n","{'num_units': 64, 'dropout': 0.1, 'optimizer': 'adamax'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:30 - loss: 0.9484 - accuracy: 0.4531WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.109526). Check your callbacks.\n","1218/1218 [==============================] - 21s 18ms/step - loss: 0.7137 - accuracy: 0.5214\n","Epoch 2/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6916 - accuracy: 0.5387\n","Epoch 3/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6854 - accuracy: 0.5522\n","Epoch 4/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6818 - accuracy: 0.5615\n","Epoch 5/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6775 - accuracy: 0.5690\n","Epoch 6/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6735 - accuracy: 0.5791\n","Epoch 7/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6690 - accuracy: 0.5877\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6636 - accuracy: 0.5959\n","Epoch 9/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6578 - accuracy: 0.6079\n","Epoch 10/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6529 - accuracy: 0.6126\n","Epoch 11/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6467 - accuracy: 0.6210\n","Epoch 12/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6403 - accuracy: 0.6266\n","Epoch 13/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6349 - accuracy: 0.6352\n","Epoch 14/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6277 - accuracy: 0.6418\n","Epoch 15/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6232 - accuracy: 0.6493\n","Epoch 16/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6164 - accuracy: 0.6534\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6120 - accuracy: 0.6586\n","Epoch 18/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6069 - accuracy: 0.6636\n","Epoch 19/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6011 - accuracy: 0.6695\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.5939 - accuracy: 0.6751\n","121/121 [==============================] - 1s 7ms/step - loss: 0.7644 - accuracy: 0.5365\n","--- Starting trial: run-14\n","{'num_units': 64, 'dropout': 0.1, 'optimizer': 'sgd'}\n","Epoch 1/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.7058 - accuracy: 0.5228\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6907 - accuracy: 0.5355\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6881 - accuracy: 0.5428\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6868 - accuracy: 0.5459\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6858 - accuracy: 0.5482\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6851 - accuracy: 0.5500\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6846 - accuracy: 0.5531\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6840 - accuracy: 0.5542\n","Epoch 9/20\n","1218/1218 [==============================] - 19s 16ms/step - loss: 0.6839 - accuracy: 0.5534\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6830 - accuracy: 0.5579\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6823 - accuracy: 0.5601\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6814 - accuracy: 0.5622\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6817 - accuracy: 0.5602\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6810 - accuracy: 0.5625\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6804 - accuracy: 0.5626\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6795 - accuracy: 0.5662\n","Epoch 17/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6799 - accuracy: 0.5640\n","Epoch 18/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6789 - accuracy: 0.5671\n","Epoch 19/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6781 - accuracy: 0.5679\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6787 - accuracy: 0.5674\n","121/121 [==============================] - 1s 7ms/step - loss: 0.6841 - accuracy: 0.5539\n","--- Starting trial: run-15\n","{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:54 - loss: 0.8134 - accuracy: 0.5078WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.130860). Check your callbacks.\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.7060 - accuracy: 0.5211\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6877 - accuracy: 0.5444\n","Epoch 3/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6839 - accuracy: 0.5569\n","Epoch 4/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6802 - accuracy: 0.5669\n","Epoch 5/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6788 - accuracy: 0.5696\n","Epoch 6/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6765 - accuracy: 0.5739\n","Epoch 7/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6735 - accuracy: 0.5783\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6708 - accuracy: 0.5857\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6669 - accuracy: 0.5937\n","Epoch 10/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6627 - accuracy: 0.5976\n","Epoch 11/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6571 - accuracy: 0.6075\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6517 - accuracy: 0.6146\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6466 - accuracy: 0.6197\n","Epoch 14/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6405 - accuracy: 0.6281\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6360 - accuracy: 0.6340\n","Epoch 16/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6292 - accuracy: 0.6408\n","Epoch 17/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6217 - accuracy: 0.6481\n","Epoch 18/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6159 - accuracy: 0.6562\n","Epoch 19/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6118 - accuracy: 0.6586\n","Epoch 20/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6056 - accuracy: 0.6660\n","121/121 [==============================] - 1s 8ms/step - loss: 0.7568 - accuracy: 0.5409\n","--- Starting trial: run-16\n","{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adamax'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:37 - loss: 0.8402 - accuracy: 0.5469WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.115290). Check your callbacks.\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.7188 - accuracy: 0.5186\n","Epoch 2/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6927 - accuracy: 0.5321\n","Epoch 3/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6877 - accuracy: 0.5449\n","Epoch 4/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6842 - accuracy: 0.5523\n","Epoch 5/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6808 - accuracy: 0.5617\n","Epoch 6/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6779 - accuracy: 0.5714\n","Epoch 7/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6756 - accuracy: 0.5750\n","Epoch 8/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6725 - accuracy: 0.5817\n","Epoch 9/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6703 - accuracy: 0.5876\n","Epoch 10/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6666 - accuracy: 0.5934\n","Epoch 11/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6644 - accuracy: 0.5959\n","Epoch 12/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6605 - accuracy: 0.6034\n","Epoch 13/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6568 - accuracy: 0.6070\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6527 - accuracy: 0.6130\n","Epoch 15/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6481 - accuracy: 0.6194\n","Epoch 16/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6449 - accuracy: 0.6226\n","Epoch 17/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6407 - accuracy: 0.6277\n","Epoch 18/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6366 - accuracy: 0.6347\n","Epoch 19/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6335 - accuracy: 0.6383\n","Epoch 20/20\n","1218/1218 [==============================] - 21s 17ms/step - loss: 0.6290 - accuracy: 0.6427\n","121/121 [==============================] - 1s 7ms/step - loss: 0.7305 - accuracy: 0.5332\n","--- Starting trial: run-17\n","{'num_units': 64, 'dropout': 0.2, 'optimizer': 'sgd'}\n","Epoch 1/20\n","   2/1218 [..............................] - ETA: 2:30 - loss: 0.9474 - accuracy: 0.5391WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.112035). Check your callbacks.\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.7240 - accuracy: 0.5149\n","Epoch 2/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6925 - accuracy: 0.5293\n","Epoch 3/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6898 - accuracy: 0.5327\n","Epoch 4/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6887 - accuracy: 0.5390\n","Epoch 5/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6882 - accuracy: 0.5414\n","Epoch 6/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6880 - accuracy: 0.5418\n","Epoch 7/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6876 - accuracy: 0.5431\n","Epoch 8/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6873 - accuracy: 0.5437\n","Epoch 9/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6869 - accuracy: 0.5461\n","Epoch 10/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6869 - accuracy: 0.5455\n","Epoch 11/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6865 - accuracy: 0.5457\n","Epoch 12/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6863 - accuracy: 0.5476\n","Epoch 13/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6860 - accuracy: 0.5482\n","Epoch 14/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6856 - accuracy: 0.5493\n","Epoch 15/20\n","1218/1218 [==============================] - 20s 17ms/step - loss: 0.6858 - accuracy: 0.5495\n","Epoch 16/20\n","1218/1218 [==============================] - 20s 16ms/step - loss: 0.6854 - accuracy: 0.5497\n","Epoch 17/20\n"," 547/1218 [============>.................] - ETA: 11s - loss: 0.6853 - accuracy: 0.5495"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5qX4uUFlIJPd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}